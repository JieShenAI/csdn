{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 支持本地部署的大模型\n",
    "# llm = ChatOpenAI(base_url=\"http://127.0.0.1:8000/v1/\", model=\"gpt-3.5-turbo\") \n",
    "llm_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_turbo = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* base_url 与 api_key 参数已添加到系统环境变量中，故无需显式传参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一种 Joke 的写法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "\n",
    "    # Alternatively, we could have specified setup as:\n",
    "\n",
    "    # setup: str                    # no default, no description\n",
    "    # setup: Annotated[str, ...]    # no default, no description\n",
    "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
    "\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若 llm 是 `gpt-3.5-turbo`，可成功得到输出，若是`gpt-4o-mini` 则会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_turbo.with_structured_output(Joke).invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 会报错\n",
    "# llm_mini.with_structured_output(Joke).invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"joke\",\n",
    "    \"description\": \"Joke to tell user.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup of the joke\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline to the joke\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "            \"default\": None,\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why was the cat sitting on the computer?',\n",
       " 'punchline': 'Because it wanted to keep an eye on the mouse!'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_turbo.with_structured_output(json_schema).invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 依然报错\n",
    "# llm_mini.with_structured_output(json_schema).invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_turbo.with_structured_output(json_schema).invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绑定多个结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Man(BaseModel):\n",
    "    \"\"\"\n",
    "    男人的信息\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(description=\"姓名\")\n",
    "    age: str = Field(description=\"年龄\")\n",
    "    interest: str = Field(description=\"兴趣爱好\")\n",
    "    colthing: str = Field(description=\"上身衣服与下身衣服\")\n",
    "    height: str = Field(description=\"身高\")\n",
    "\n",
    "\n",
    "class Woman(BaseModel):\n",
    "    \"\"\"\n",
    "    女人的信息\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(description=\"姓名\")\n",
    "    age: str = Field(description=\"年龄\")\n",
    "    interest: str = Field(description=\"兴趣爱好\")\n",
    "    colthing: str = Field(description=\"上身衣服与下身衣服\")\n",
    "    height: str = Field(description=\"身高\")\n",
    "\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    final_output: Union[Man, Woman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(final_output=Man(name='张伟', age='30', interest='运动，旅行，读书', colthing='白色衬衫，深色牛仔裤', height='175cm'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_turbo.with_structured_output(Person).invoke(\"帮我生成一个男人的信息\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(final_output=Man(name='李华', age='28', interest='阅读，旅行，烹饪', colthing='白色衬衫和黑色裙子', height='165cm'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_turbo.with_structured_output(Person).invoke(\"帮我生成一个女人的信息\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse\n",
    "\n",
    "为了解决一些模型不支持结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Man(BaseModel):\n",
    "    \"\"\"\n",
    "    男人的信息\n",
    "    \"\"\"\n",
    "    name: str = Field(description=\"姓名\")\n",
    "    age: str = Field(description=\"年龄\")\n",
    "    interest: str = Field(description=\"兴趣爱好\")\n",
    "    colthing: str = Field(description=\"上身衣服与下身衣服\")\n",
    "    height: str = Field(description=\"身高\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"hello {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='hello world')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"name\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Man"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='李四' age='28' interest='旅游与摄影' colthing='蓝色衬衫与卡其色长裤' height='175cm'\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "    生成一个男人的信息。以json格式返回，包含姓名、年龄、兴趣爱好、上身衣服与下身衣服、身高。格式如下:\n",
    "    ```json\n",
    "    {{\n",
    "        \"name\": \"张三\",\n",
    "        \"age\": \"20\",\n",
    "        \"interest\": \"打篮球\",\n",
    "        \"colthing\": \"白色T恤与黑色裤子\",\n",
    "        \"height\": \"180cm\"\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\".strip()\n",
    ")\n",
    "parser = PydanticOutputParser(pydantic_object=Man)\n",
    "chain = prompt_template | llm_mini | parser\n",
    "man_info = chain.invoke({})\n",
    "if man_info:\n",
    "    print(man_info)\n",
    "else:\n",
    "    print(\"没有返回结果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Man(name='李四', age='28', interest='旅游与摄影', colthing='蓝色衬衫与卡其色长裤', height='175cm')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写法一**，直接写入到提示词中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "system_msg = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
    "\n",
    "examples = \"\"\"\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "{system_msg}\n",
    "\n",
    "Here are some examples of jokes:\n",
    "{examples}\n",
    "\n",
    "example_user: {input}\n",
    "\"\"\".strip()\n",
    ")\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain的提示词模板可以使用 `invoke`和`format` 进行提示词填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看填充完成后的提示词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a hilarious comedian. Your specialty is knock-knock jokes. \n",
      "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
      "\n",
      "Here are some examples of jokes:\n",
      "example_user: Tell me a joke about planes\n",
      "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
      "\n",
      "example_user: Tell me another joke about planes\n",
      "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
      "\n",
      "example_user: Now about caterpillars\n",
      "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\n",
      "example_user: what's something funny about woodpeckers\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke({\n",
    "    \"system_msg\": system_msg,\n",
    "    \"examples\": examples,\n",
    "    \"input\": \"what's something funny about woodpeckers\",\n",
    "}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a hilarious comedian. Your specialty is knock-knock jokes. \n",
      "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
      "\n",
      "Here are some examples of jokes:\n",
      "example_user: Tell me a joke about planes\n",
      "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
      "\n",
      "example_user: Tell me another joke about planes\n",
      "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
      "\n",
      "example_user: Now about caterpillars\n",
      "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\n",
      "example_user: what's something funny about woodpeckers\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    prompt.format(\n",
    "        system_msg=system_msg,\n",
    "        examples=examples,\n",
    "        input=\"what's something funny about woodpeckers\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Woodpecker', punchline=\"Woodpecker knocking at your door? It's just trying to show you its new peck-formance!\", rating=7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_chain1 = prompt | llm_mini.with_structured_output(Joke)\n",
    "few_shot_chain1.invoke(\n",
    "    {\n",
    "        \"system_msg\": system_msg,\n",
    "        \"examples\": examples,\n",
    "        \"input\": \"what's something funny about woodpeckers\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有 few_shot, gpt-4o-mini 模型会报错，加上 few-shot gpt-4o-mini 模型可以正常得到结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写法二**，`FewShotPromptTemplate`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "system_msg = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\"\"\".strip()\n",
    "\n",
    "# 定义格式化单个示例的 PromptTemplate\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Q: {query}\\nA: {{{answer}}}\",\n",
    ")\n",
    "\n",
    "# 示例数据\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Tell me a joke about planes\",\n",
    "        \"answer\": {\"setup\": \"Why don\\'t planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2},\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tell me another joke about planes\",\n",
    "        \"answer\": {\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10},\n",
    "    }\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    example[\"answer\"] = json.dumps(example[\"answer\"])\n",
    "\n",
    "# 构建 FewShotPromptTemplate\n",
    "few_shot_prompt2 = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    prefix=system_msg,\n",
    "    suffix=\"Q: {input}\\nA:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a hilarious comedian. Your specialty is knock-knock jokes. Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
      "\n",
      "Here are some examples of jokes:\n",
      "\n",
      "Q: Tell me a joke about planes\n",
      "A: {\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}\n",
      "\n",
      "Q: Tell me another joke about planes\n",
      "A: {\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}\n",
      "\n",
      "Q: Now about caterpillars\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt2.invoke({\"input\": \"Now about caterpillars\"}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值得注意的是 examples的answer是一个字典。为了不让langchain报错，针对 PromptTemplate 我是这些写的：\n",
    "\n",
    "`\"Q: {query}\\nA: {{{answer}}}\"`\n",
    "\n",
    "使用了三个括号，把answer包住。大家记住`{{`是`{`的转义，然后再去理解三个括号就行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Woodpecker', punchline=\"Woodpecker who's always knocking on wood for good luck!\", rating=8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_chain2 = few_shot_prompt2 | llm_mini.with_structured_output(Joke)\n",
    "few_shot_chain2.invoke(\n",
    "    {\n",
    "        \"input\": \"what's something funny about woodpeckers\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类的结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diy 实现一个文本分类，经济、工业、产业等\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "class TextCLS(BaseModel):\n",
    "    \"\"\"\n",
    "    文本分类的结构化输出\n",
    "    \"\"\"\n",
    "\n",
    "    keyword: List[str] = Field(description=\"问题中出现的与分类相关的关键词\")\n",
    "    reason: str = Field(description=\"分类的原因\")\n",
    "    label: str = Field(description=\"文本分类label\")\n",
    "    \n",
    "schema = [\"经济\", \"民生\", \"产业\", \"绿色发展\", \"军事\", \"其他\"]\n",
    "\n",
    "system_msg = \"请你完成文本分类任务，按照要求完成关键词提取，输出分类原因与最终的类别。文本的类别是：{schema}\"\n",
    "\n",
    "# 定义格式化单个示例的 PromptTemplate\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Q: {query}\\nA: {answer}\",\n",
    ")\n",
    "\n",
    "# 示例数据\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"武汉市今年GDP上涨2%\",\n",
    "        \"answer\": '{{\"keyword\": [\"GDP\"], \"reason\": \"GDP与经济相关\", \"label\": \"经济\"}}',\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"氢能产业园区的相关配套措施完善，园区内有很多氢能领域龙头企业\",\n",
    "        \"answer\": \"\"\"{{\n",
    "                \"keyword\": [\"氢能产业园区\", \"氢能领域龙头企业\"],\n",
    "                \"reason\": \"问题中的氢能产业园区与氢能领域龙头企业都与产业相关\",\n",
    "                \"label\": \"产业\",\n",
    "            }}\"\"\".strip(),\n",
    "    },\n",
    "]\n",
    "\n",
    "# 构建 FewShotPromptTemplate\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    prefix=system_msg,\n",
    "    suffix=\"Q: {input}\\nA:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请你完成文本分类任务，按照要求完成关键词提取，输出分类原因与最终的类别。文本的类别是：['经济', '民生', '产业', '绿色发展', '军事', '其他']\n",
      "\n",
      "Q: 武汉市今年GDP上涨2%\n",
      "A: {\"keyword\": [\"GDP\"], \"reason\": \"GDP与经济相关\", \"label\": \"经济\"}\n",
      "\n",
      "Q: 氢能产业园区的相关配套措施完善，园区内有很多氢能领域龙头企业\n",
      "A: {\n",
      "                \"keyword\": [\"氢能产业园区\", \"氢能领域龙头企业\"],\n",
      "                \"reason\": \"问题中的氢能产业园区与氢能领域龙头企业都与产业相关\",\n",
      "                \"label\": \"产业\",\n",
      "            }\n",
      "\n",
      "Q: 武汉市今年GDP上涨2%\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "# 一次性传递全部参数\n",
    "prompt = few_shot_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"武汉市今年GDP上涨2%\",\n",
    "        \"schema\": schema,\n",
    "    }\n",
    ")\n",
    "print(prompt.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示词模板使用format与invoke方法来格式化字符串:\n",
    "\n",
    "```python\n",
    "prompt = PromptTemplate.from_template(\"{foo}{bar}\")\n",
    "prompt.invoke({\"foo\": \"hello\", \"bar\": \"world\"})\n",
    "prompt.format(foo=\"hello\",bar=\"world\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='请你完成文本分类任务，按照要求完成关键词提取，输出分类原因与最终的类别。文本的类别是：[\\'经济\\', \\'民生\\', \\'产业\\', \\'绿色发展\\', \\'军事\\', \\'其他\\']\\n\\nQ: 武汉市今年GDP上涨2%\\nA: {\"keyword\": [\"GDP\"], \"reason\": \"GDP与经济相关\", \"label\": \"经济\"}\\n\\nQ: 氢能产业园区的相关配套措施完善，园区内有很多氢能领域龙头企业\\nA: {\\n                \"keyword\": [\"氢能产业园区\", \"氢能领域龙头企业\"],\\n                \"reason\": \"问题中的氢能产业园区与氢能领域龙头企业都与产业相关\",\\n                \"label\": \"产业\",\\n            }\\n\\nQ: 武汉市今年GDP上涨2%\\nA:')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 部分提示词: 设置文本分类的label，不用每一次都传递schema进去\n",
    "partial_prompt = few_shot_prompt.partial(schema=schema)\n",
    "partial_prompt.invoke({\"input\":\"武汉市今年GDP上涨2%\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanin = partial_prompt | llm_mini.with_structured_output(TextCLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCLS(keyword=['生产总值'], reason='生产总值与经济相关，反映经济增长情况', label='经济')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chanin.invoke(\"北京市今年的生产总值提高了5个百分点\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCLS(keyword=['氢能产业园区', '投资氢能产业'], reason='氢能产业园区的发展和企业投资都与产业相关', label='产业')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chanin.invoke(\"今年的氢能产业园区发展迅速，很多企业都在投资氢能产业\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCLS(keyword=['爱'], reason='文本为情感表达，与具体类别无关', label='其他')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chanin.invoke(\"你爱我吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
