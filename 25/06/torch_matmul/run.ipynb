{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多维的矩阵乘法细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 @ a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor([1, 2])\n",
    "res1 = torch.matmul(a1, a1)\n",
    "print(res1)\n",
    "print(res1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mm 支持二维矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([[1, 2]])\n",
    "print(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "res2 = torch.matmul(a2, a2.transpose(-2, -1))\n",
    "print(res2)\n",
    "print(res2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "res2_1 = torch.mm(a2, a2.transpose(-2, -1))\n",
    "print(res2_1)\n",
    "print(res2_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.matmul 与 torch.mm 在二维矩阵运算上的结果一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三维矩阵（高维矩阵乘法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.bmm 支持三维矩阵乘法，不支持更高维度的矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高维的矩阵的乘法：\n",
    "\n",
    "底层的两个维度的shape 需要满足做矩阵运算的条件。只在底层的两个维度上做矩阵乘法，矩阵高维度的shape不发生变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家容易一听到矩阵乘法，都知道矩阵要做转置，对于二维矩阵乘法都很了解。\n",
    "但对于高维矩阵乘法弄不清楚，不知道高维矩阵乘法是怎么在计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1. 做矩阵乘法的高维度通常都是一样的\n",
    "a3 = torch.randn(2, 3, 2)\n",
    "print(a3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3187, -2.1205],\n",
       "          [-0.1837, -0.2859],\n",
       "          [-0.5481, -1.2962]],\n",
       " \n",
       "         [[ 0.0716,  1.0135],\n",
       "          [-0.4479,  1.8286],\n",
       "          [-0.4443, -0.3185]]]),\n",
       " torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3, a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3187, -0.1837, -0.5481],\n",
       "          [-2.1205, -0.2859, -1.2962]],\n",
       " \n",
       "         [[ 0.0716, -0.4479, -0.4443],\n",
       "          [ 1.0135,  1.8286, -0.3185]]]),\n",
       " torch.Size([2, 2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.transpose(-1, -2), a3.transpose(-1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.5979,  0.6648,  2.9231],\n",
      "         [ 0.6648,  0.1155,  0.4713],\n",
      "         [ 2.9231,  0.4713,  1.9805]],\n",
      "\n",
      "        [[ 1.0323,  1.8212, -0.3546],\n",
      "         [ 1.8212,  3.5445, -0.3834],\n",
      "         [-0.3546, -0.3834,  0.2988]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "res3 = torch.bmm(\n",
    "    a3,\n",
    "    a3.transpose(-1, -2)\n",
    ")\n",
    "print(res3)\n",
    "print(res3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.5979,  0.6648,  2.9231],\n",
      "         [ 0.6648,  0.1155,  0.4713],\n",
      "         [ 2.9231,  0.4713,  1.9805]],\n",
      "\n",
      "        [[ 1.0323,  1.8212, -0.3546],\n",
      "         [ 1.8212,  3.5445, -0.3834],\n",
      "         [-0.3546, -0.3834,  0.2988]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "res3 = torch.matmul(\n",
    "    a3,\n",
    "    a3.transpose(-1, -2)\n",
    ")\n",
    "print(res3)\n",
    "print(res3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a3 的 shape是(2, 3, 2)，a3 底层的两个维度做转置之后变成(2, 2, 3)，才可以做矩阵乘法。\n",
    "可以发现第一位的数字都是2。\n",
    "\n",
    "高维矩阵做乘法的时候，最底层两个维度要做足做矩阵乘法的条件，高维的shape两者都是一样的。如果不一致，需要是1，1可以做广播。\n",
    "\n",
    "\n",
    "\n",
    "**高维矩阵乘法解读**：本质上是最后两个维度的矩阵计算。矩阵高维的shape不会发生变化。如果把最后两个维度的小矩阵抽象成为一个点的话，高维的矩阵乘法，本质上与向量乘法是一样的，都是把对应位置的点，直接相乘。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6557,  1.0518,  0.3055],\n",
       "         [-0.2876, -2.5104, -1.4417],\n",
       "         [ 1.4447, -0.1799,  0.4602]],\n",
       "\n",
       "        [[ 0.2971,  0.0060, -0.2612],\n",
       "         [-0.9089,  1.0824,  0.7131],\n",
       "         [ 0.0929, -0.7898, -0.0199]],\n",
       "\n",
       "        [[ 0.0027,  1.2031,  0.1543],\n",
       "         [-0.5603, -1.8567, -0.1302],\n",
       "         [ 0.3978, -0.9356, -0.1977]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.randn(1, 3, 2)\n",
    "t2 = torch.randn(3, 2, 3)\n",
    "t1 @ t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3304, -1.4246, -1.4416]],\n",
       "\n",
       "        [[-0.1239, -1.6294, -0.3421]],\n",
       "\n",
       "        [[-2.3254, -1.6569, -1.6612]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 1, 2) @ torch.randn(3, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6557,  1.0518,  0.3055],\n",
       "         [-0.2876, -2.5104, -1.4417],\n",
       "         [ 1.4447, -0.1799,  0.4602]],\n",
       "\n",
       "        [[ 0.2971,  0.0060, -0.2612],\n",
       "         [-0.9089,  1.0824,  0.7131],\n",
       "         [ 0.0929, -0.7898, -0.0199]],\n",
       "\n",
       "        [[ 0.0027,  1.2031,  0.1543],\n",
       "         [-0.5603, -1.8567, -0.1302],\n",
       "         [ 0.3978, -0.9356, -0.1977]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat((t1, t1, t1)) @ t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高维矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_matrix1 = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "high_matrix2 = torch.randn(2, 3, 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用 @ 做矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_result = high_matrix1 @ high_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(high_matrix1, high_matrix2) == (high_matrix1 @ high_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把最后两个维度看成一个点。看两个矩阵对应位置的点相乘\n",
    "\n",
    "shape(2, 3, 4, 5)与shape(2, 3, 5, 4)的矩阵相乘，若把最后两个维度看成一个点，\n",
    "\n",
    "就可以类比为 (2, 3) 与 (2, 3)的两个矩阵做向量乘法，就是对应位置的点做乘法，不需要考虑shape的变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(high_matrix1[1][2] @  high_matrix2[1][2]) == high_result[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
