{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ee94b2",
   "metadata": {},
   "source": [
    "向量embedding模型的底层解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc897a8",
   "metadata": {},
   "source": [
    "加载 bge-m3 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92eac93b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T02:57:39.426966Z",
     "start_time": "2025-06-14T02:57:39.412658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /Users/jie/.cache/modelscope/hub/models/BAAI/bge-m3\n"
     ]
    }
   ],
   "source": [
    "# 下载热门的embedding模型\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('BAAI/bge-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e805bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ec3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello world!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9572a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03437407687306404, 0.029861997812986374, -0.041066382080316544, 0.0028893225826323032, -0.020066309720277786, -0.03695249184966087, -0.038797527551651, -0.05372311547398567, 0.011357544921338558, -0.0034280770923942327]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_query(text)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103dcc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03437407687306404, 0.029861997812986374, -0.041066382080316544, 0.0028893225826323032, -0.020066309720277786, -0.03695249184966087, -0.038797527551651, -0.05372311547398567, 0.011357544921338558, -0.0034280770923942327]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_documents([text])[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2514e2",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67da02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert 加载 \n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f72898",
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_m3_bert = AutoModel.from_pretrained(model_dir)\n",
    "bge_m3_tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b932ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = bge_m3_tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd6768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.9034,  0.7848, -1.0793,  ...,  0.6585, -0.9023,  0.2505],\n",
       "         [ 0.3974, -0.1502, -0.8096,  ...,  1.5423, -0.6413,  0.4494],\n",
       "         [ 0.0902,  0.2658, -0.8696,  ...,  1.3465, -0.2546,  0.5970],\n",
       "         [-0.6971,  0.5654, -0.2306,  ...,  1.0564, -0.2211,  0.0615],\n",
       "         [ 0.1637,  0.3918, -0.7434,  ...,  1.4434, -0.7046,  0.3979],\n",
       "         [-0.0837,  0.7006, -0.8004,  ...,  1.2811, -1.2167,  0.4276]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8678,  0.2324,  0.1832,  ..., -0.0287,  0.6174,  0.1894]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = bge_m3_bert(**tokens)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1775369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f049ca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_tensor = output.last_hidden_state[:, 0]\n",
    "cls_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea293c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0344,  0.0299, -0.0411,  ...,  0.0251, -0.0343,  0.0095]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.normalize(cls_tensor, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ba298",
   "metadata": {},
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "246bf285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_state.shape torch.Size([1, 6, 1024])\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "hidden_state = output.last_hidden_state\n",
    "mask = tokens[\"attention_mask\"]\n",
    "\n",
    "print(\"hidden_state.shape\", hidden_state.shape)\n",
    "print( mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74595d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * 对应位置的数据做乘法, 和mask用*做乘法表示填充部分token不参与计算\n",
    "s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)\n",
    "d = mask.sum(axis=1, keepdim=True).float()\n",
    "\n",
    "(s / d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a43ec3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 下述代码参考自：FlagEmbedding 包的实现\n",
    "\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        normlized: bool = False,\n",
    "        sentence_pooling_method: str = \"mean\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        # self.cross_entropy = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        self.sentence_pooling_method = sentence_pooling_method\n",
    "        self.normlized = normlized\n",
    "\n",
    "    def sentence_embedding(self, hidden_state, mask):\n",
    "        if self.sentence_pooling_method == \"mean\":\n",
    "            s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)\n",
    "            d = mask.sum(axis=1, keepdim=True).float()\n",
    "            return s / d\n",
    "        elif self.sentence_pooling_method == \"cls\":\n",
    "            return hidden_state[:, 0]\n",
    "\n",
    "    def encode(self, features):\n",
    "        if features is None:\n",
    "            return None\n",
    "        psg_out = self.model(**features, return_dict=True)\n",
    "        p_reps = self.sentence_embedding(\n",
    "            psg_out.last_hidden_state, features[\"attention_mask\"]\n",
    "        )\n",
    "        if self.normlized:\n",
    "            p_reps = torch.nn.functional.normalize(p_reps, dim=-1)\n",
    "        return p_reps.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adfdc8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03437407687306404,\n",
       " 0.029861997812986374,\n",
       " -0.041066382080316544,\n",
       " 0.0028893225826323032,\n",
       " -0.020066309720277786,\n",
       " -0.03695249184966087,\n",
       " -0.038797527551651,\n",
       " -0.05372311547398567,\n",
       " 0.011357544921338558,\n",
       " -0.0034280770923942327]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_documents([text])[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e209f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0344,  0.0299, -0.0411,  ...,  0.0251, -0.0343,  0.0095]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncoderModel(model_dir, sentence_pooling_method=\"cls\", normlized=True).encode(\n",
    "    bge_m3_tokenizer(text, return_tensors=\"pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52fddc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0068,  0.0168, -0.0298,  ...,  0.0483, -0.0259,  0.0144]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncoderModel(model_dir, sentence_pooling_method=\"mean\", normlized=True).encode(\n",
    "    bge_m3_tokenizer(text, return_tensors=\"pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cdd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
