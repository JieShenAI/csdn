{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7102d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from src.arguments import (\n",
    "    ModelArguments,\n",
    "    DataArguments,\n",
    "    RetrieverTrainingArguments as TrainingArguments,\n",
    ")\n",
    "from src.data import TrainDatasetForEmbedding, EmbedCollator\n",
    "from src.modeling import BiEncoderModel\n",
    "# from trainer import BiTrainer\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1a4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa3793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/jie/.cache/modelscope/hub/models/AI-ModelScope/bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 10:04:17,923 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n"
     ]
    }
   ],
   "source": [
    "#Model Download\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('AI-ModelScope/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9963fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_d = {\n",
    "    \"output_dir\": \"output\",\n",
    "    # \"model_name_or_path\": \"BAAI/bge-large-zh-v1.5\",\n",
    "    \"model_name_or_path\": model_dir,\n",
    "    \"train_data\": \"./toy_finetune_data.jsonl\",\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"fp16\": True,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"dataloader_drop_last\": True,\n",
    "    \"normlized\": True,\n",
    "    \"temperature\": 0.02,\n",
    "    \"query_max_len\": 64,\n",
    "    \"passage_max_len\": 256,\n",
    "    \"train_group_size\": 4,\n",
    "    \"negatives_cross_device\": False,\n",
    "    \"logging_steps\": 10,\n",
    "    \"query_instruction_for_retrieval\": \"为这个句子生成表示以用于检索相关文章：\",\n",
    "    \"save_safetensors\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22649922",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "model_args, data_args, training_args = parser.parse_dict(args_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685f4f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrieverTrainingArguments(output_dir='output', overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, eval_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, lr_scheduler_kwargs={}, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='output/runs/Jun06_22-52-02_pku', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=10, logging_nan_inf_filter=True, save_strategy=<SaveStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, save_safetensors=False, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=True, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=True, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name='output', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, tp_size=0, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=None, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend='auto', evaluation_strategy=None, push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, eval_use_gather_object=False, average_tokens_across_devices=False, negatives_cross_device=False, temperature=0.02, fix_position_embedding=False, sentence_pooling_method='cls', normlized=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1c1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    (\n",
    "        model_args.tokenizer_name\n",
    "        if model_args.tokenizer_name\n",
    "        else model_args.model_name_or_path\n",
    "    ),\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    (\n",
    "        model_args.config_name\n",
    "        if model_args.config_name\n",
    "        else model_args.model_name_or_path\n",
    "    ),\n",
    "    num_labels=num_labels,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "# model = BiEncoderModel(\n",
    "#     model_name=model_args.model_name_or_path,\n",
    "#     normlized=training_args.normlized,\n",
    "#     sentence_pooling_method=training_args.sentence_pooling_method,\n",
    "#     negatives_cross_device=training_args.negatives_cross_device,\n",
    "#     temperature=training_args.temperature,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273ec607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDatasetForEmbedding(args=data_args, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5fd746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('为这个句子生成表示以用于检索相关文章：Five women walk along a beach wearing flip-flops.',\n",
       " ['Some women with flip-flops on, are walking along the beach',\n",
       "  'The man is talking about hawaii.',\n",
       "  \"She's not going to court to clear her record.\",\n",
       "  'There was a reform in 1996.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b71b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = EmbedCollator(\n",
    "    tokenizer,\n",
    "    query_max_len=data_args.query_max_len,\n",
    "    passage_max_len=data_args.passage_max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9047c5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'input_ids': tensor([[  101,   100,   100,   100,   100,  1816,  1910,  1854,   100,  1923,\n",
       "            100,   100,   100,   100,   100,  1919,   100,  1861,  1932,  1993,\n",
       "           2274,  2308,  3328,  2247,  1037,  3509,  4147, 11238,  1011, 28583,\n",
       "           2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " 'passage': {'input_ids': tensor([[  101,  2070,  2308,  2007, 11238,  1011, 28583,  2015,  2006,  1010,\n",
       "           2024,  3788,  2247,  1996,  3509,   102],\n",
       "         [  101,  1037,  2177,  1997,  2111,  3248,  7454,  1012,   102,     0,\n",
       "              0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2016,  1005,  1055,  2025,  2183,  2000,  2457,  2000,  3154,\n",
       "           2014,  2501,  1012,   102,     0,     0],\n",
       "         [  101,  1996,  1018,  2308,  2024,  3564,  2006,  1996,  3509,  1012,\n",
       "            102,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator([train_dataset[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2adf96c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAAI/bge-large-zh-v1.5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args.model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6066e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d75d6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "query, passage = data_collator([train_dataset[0]]).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "779b047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   711,  6821,   702,  1368,  2094,  4495,  2768,  6134,  4850,\n",
       "           809,  4500,   754,  3466,  5164,  4685,  1068,  3152,  4995,  8038,\n",
       "         12706, 12912,   165, 11346,  9266,  9142,   143,  9983, 12679,  8221,\n",
       "           148,  8636,  8187,   118,   148,  8897,  8525,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f063c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model = BiEncoderModel(\n",
    "    model_name=model_args.model_name_or_path,\n",
    "    normlized=training_args.normlized,\n",
    "    sentence_pooling_method=\"mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92a71b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7693, 0.2740, 0.5726, 0.2958]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = mean_model.compute_similarity(mean_model.encode(query), mean_model.encode(passage))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54bca68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0343,  0.0061, -0.0474,  ..., -0.0099, -0.0407,  0.0079]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41b83ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5201e-02,  1.6923e-02, -2.8226e-02,  ..., -1.4305e-02,\n",
       "          2.4664e-02,  8.6464e-06],\n",
       "        [ 2.5590e-02,  5.7111e-02, -4.5425e-02,  ...,  1.3755e-02,\n",
       "          1.1986e-02, -3.4164e-02],\n",
       "        [-1.4720e-02,  2.2096e-02, -2.6135e-02,  ..., -2.0131e-02,\n",
       "         -9.4332e-03, -1.5504e-02],\n",
       "        [-1.5406e-02,  1.2138e-02,  2.2544e-02,  ..., -5.2548e-02,\n",
       "         -2.6954e-02,  2.0775e-04]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_model.encode(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b635222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(q_reps=tensor([[ 0.0343,  0.0061, -0.0474,  ..., -0.0099, -0.0407,  0.0079]],\n",
       "       grad_fn=<DivBackward0>), p_reps=tensor([[ 2.5201e-02,  1.6923e-02, -2.8226e-02,  ..., -1.4305e-02,\n",
       "          2.4664e-02,  8.6464e-06],\n",
       "        [ 2.5590e-02,  5.7111e-02, -4.5425e-02,  ...,  1.3755e-02,\n",
       "          1.1986e-02, -3.4164e-02],\n",
       "        [-1.4720e-02,  2.2096e-02, -2.6135e-02,  ..., -2.0131e-02,\n",
       "         -9.4332e-03, -1.5504e-02],\n",
       "        [-1.5406e-02,  1.2138e-02,  2.2544e-02,  ..., -5.2548e-02,\n",
       "         -2.6954e-02,  2.0775e-04]], grad_fn=<DivBackward0>), loss=tensor(1.1163, grad_fn=<NllLossBackward0>), scores=tensor([[0.7693, 0.2740, 0.5726, 0.2958]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_model(query=query, passage=passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ae02ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b8f8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    res = mean_model(query=query, passage=passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e2cdd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(q_reps=tensor([[ 0.0343,  0.0061, -0.0474,  ..., -0.0099, -0.0407,  0.0079]]), p_reps=tensor([[ 2.5201e-02,  1.6923e-02, -2.8226e-02,  ..., -1.4305e-02,\n",
       "          2.4664e-02,  8.6464e-06],\n",
       "        [ 2.5590e-02,  5.7111e-02, -4.5425e-02,  ...,  1.3755e-02,\n",
       "          1.1986e-02, -3.4164e-02],\n",
       "        [-1.4720e-02,  2.2096e-02, -2.6135e-02,  ..., -2.0131e-02,\n",
       "         -9.4332e-03, -1.5504e-02],\n",
       "        [-1.5406e-02,  1.2138e-02,  2.2544e-02,  ..., -5.2548e-02,\n",
       "         -2.6954e-02,  2.0775e-04]]), loss=tensor(1.1163), scores=tensor([[0.7693, 0.2740, 0.5726, 0.2958]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd65cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b43dd9",
   "metadata": {},
   "source": [
    "## batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fded9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_query, batch_passage = data_collator([train_dataset[i] for i in range(3)]).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38295077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,   100,   100,   100,  1816,  1910,  1854,   100,  1923,\n",
       "           100,   100,   100,   100,   100,  1919,   100,  1861,  1932,  1993,\n",
       "          2274,  2308,  3328,  2247,  1037,  3509,  4147, 11238,  1011, 28583,\n",
       "          2015,  1012,   102,     0,     0,     0],\n",
       "        [  101,   100,   100,   100,   100,  1816,  1910,  1854,   100,  1923,\n",
       "           100,   100,   100,   100,   100,  1919,   100,  1861,  1932,  1993,\n",
       "          1037,  2450,  3061,  2006,  1037,  2152,  7656,  2006,  2028,  4190,\n",
       "          2559,  2058,  1037,  2314,  1012,   102],\n",
       "        [  101,   100,   100,   100,   100,  1816,  1910,  1854,   100,  1923,\n",
       "           100,   100,   100,   100,   100,  1919,   100,  1861,  1932,  1993,\n",
       "          2048,  2450,  2024,  2652,  5693,  1025,  2028,  1037, 12089,  1010,\n",
       "          1996,  2060,  1037,  6710,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3c11c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(q_reps=tensor([[ 0.0264, -0.0110, -0.0012,  ..., -0.0346,  0.0140, -0.0548],\n",
       "        [ 0.0115, -0.0143, -0.0160,  ..., -0.0351,  0.0100, -0.0383],\n",
       "        [ 0.0068,  0.0037, -0.0002,  ..., -0.0284,  0.0262, -0.0567]],\n",
       "       grad_fn=<DivBackward0>), p_reps=tensor([[ 0.0601, -0.0266, -0.0091,  ..., -0.0334, -0.0120, -0.0295],\n",
       "        [ 0.0505,  0.0308, -0.0269,  ..., -0.0146,  0.0410, -0.0189],\n",
       "        [ 0.0470, -0.0370,  0.0343,  ..., -0.0092,  0.0043, -0.0207],\n",
       "        ...,\n",
       "        [ 0.0046, -0.0206, -0.0217,  ..., -0.0370,  0.0110, -0.0384],\n",
       "        [ 0.0554, -0.0042, -0.0180,  ..., -0.0143, -0.0018, -0.0145],\n",
       "        [-0.0126, -0.0385,  0.0013,  ..., -0.0295, -0.0036,  0.0067]],\n",
       "       grad_fn=<DivBackward0>), loss=tensor(2.4021, grad_fn=<NllLossBackward0>), scores=tensor([[0.5581, 0.4210, 0.3527, 0.4637, 0.5158, 0.3126, 0.4513, 0.4229, 0.4140,\n",
       "         0.2105, 0.4903, 0.3946],\n",
       "        [0.5212, 0.4166, 0.3669, 0.4586, 0.5332, 0.3186, 0.4538, 0.4296, 0.4035,\n",
       "         0.2310, 0.4357, 0.4211],\n",
       "        [0.4923, 0.4345, 0.3714, 0.4525, 0.4658, 0.3053, 0.4426, 0.4184, 0.4044,\n",
       "         0.2148, 0.4264, 0.4281]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_model(query=batch_query, passage=batch_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc68972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5581, 0.4210, 0.3527, 0.4637, 0.5158, 0.3126, 0.4513, 0.4229, 0.4140,\n",
       "         0.2105, 0.4903, 0.3946],\n",
       "        [0.5212, 0.4166, 0.3669, 0.4586, 0.5332, 0.3186, 0.4538, 0.4296, 0.4035,\n",
       "         0.2310, 0.4357, 0.4211],\n",
       "        [0.4923, 0.4345, 0.3714, 0.4525, 0.4658, 0.3053, 0.4426, 0.4184, 0.4044,\n",
       "         0.2148, 0.4264, 0.4281]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_scores = mean_model.compute_similarity(\n",
    "    mean_model.encode(batch_query),\n",
    "    mean_model.encode(batch_passage),\n",
    ")\n",
    "batch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b079cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4021, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(batch_scores, torch.tensor([0, 1, 2]) * data_args.train_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664010e",
   "metadata": {},
   "source": [
    "验证 hf 使用 mean 还是 cls 在计算encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9269031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87135/1032096793.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/jie/anaconda3/envs/agent/lib/python3.11/site-packages/accelerate/accelerator.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=mean_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=EmbedCollator(\n",
    "        tokenizer,\n",
    "        query_max_len=data_args.query_max_len,\n",
    "        passage_max_len=data_args.passage_max_len,\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23270bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.861200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25, training_loss=1.89400390625, metrics={'train_runtime': 4.2306, 'train_samples_per_second': 11.819, 'train_steps_per_second': 5.909, 'total_flos': 0.0, 'train_loss': 1.89400390625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744a9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84e339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.is_world_process_zero()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
