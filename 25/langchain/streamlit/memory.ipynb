{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uuid\n",
    "\n",
    "# # 设置一个唯一的 session_id\n",
    "# if 'session_id' not in st.session_state:\n",
    "#     st.session_state.session_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 避免key泄漏\n",
    "base_url = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 16:54:52.715 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:52.716 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-03-31 16:54:52.716 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:52.716 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:52.716 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import StreamlitChatMessageHistory\n",
    "\n",
    "history = StreamlitChatMessageHistory(key=\"chat_messages\")\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 16:54:58.922 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:58.923 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:58.924 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 16:54:58.926 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "/tmp/ipykernel_103923/1863846972.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\", chat_memory=msgs)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n",
    "\n",
    "# 可选地，为存储消息指定自己的 session_state 键\n",
    "msgs = StreamlitChatMessageHistory(key=\"special_app_key\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", chat_memory=msgs)\n",
    "if len(msgs.messages) == 0:\n",
    "    msgs.add_ai_message(\"How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"You are an AI chatbot having a conversation with a human.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n",
    "\n",
    "# 像往常一样将内存添加到 LLMChain 中\n",
    "llm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "for msg in msgs.messages:\n",
    "    st.chat_message(msg.type).write(msg.content)\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"human\").write(prompt)\n",
    "\n",
    "    # 像往常一样，当调用 Chain 时，新消息将添加到 StreamlitChatMessageHistory 中。\n",
    "    response = llm_chain.run(prompt)\n",
    "    st.chat_message(\"ai\").write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
